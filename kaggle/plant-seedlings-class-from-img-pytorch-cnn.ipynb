{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Seedlings Classification from Images - PyTorch CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Building a CNN Classificator with PyTorch to classify plant seedlings from differently sized images.\n",
    "\n",
    "Data: Plant Seedlings Classification via Kaggle (https://www.kaggle.com/competitions/plant-seedlings-classification)\n",
    "\n",
    "Procedure:\n",
    "- Previewing images\n",
    "- Analyze Height, Width, Aspect Ratios\n",
    "- Resize\n",
    "- Create masks, apply masks, sharpen\n",
    "- Normalize\n",
    "- Encode Labels\n",
    "- Train/Validation Split\n",
    "- Create DataLoader\n",
    "- Create CNN Model with pytorch\n",
    "- Train Model\n",
    "- Evaluate Loss, micro-F1, and Accuracy over Time\n",
    "- Predict Labels for Test Data and create submission file\n",
    "\n",
    "Others:\n",
    "- Compatible with Google Colab and Kaggle as runtime\n",
    "- CUDA support\n",
    "\n",
    "Sources used:\n",
    "- https://www.kaggle.com/code/gaborvecsei/plant-seedlings-fun-with-computer-vision\n",
    "- https://www.kaggle.com/code/gaborfodor/seedlings-pretrained-keras-models\n",
    "- https://machinelearningknowledge.ai/pytorch-conv2d-explained-with-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:06:17.412632Z",
     "iopub.status.busy": "2023-09-19T11:06:17.412267Z",
     "iopub.status.idle": "2023-09-19T11:06:31.239084Z",
     "shell.execute_reply": "2023-09-19T11:06:31.237823Z",
     "shell.execute_reply.started": "2023-09-19T11:06:17.412605Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Running on {DEVICE}')\n",
    "\n",
    "# running in google colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    NUM_EPOCHS = 50\n",
    "    !pip install torchviz\n",
    "    BASE_PATH = './drive/MyDrive/Colab/data/'\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "# running interactively in kaggle\n",
    "elif get_ipython().config.IPKernelApp.connection_file.startswith('/root/.local/share'):\n",
    "    NUM_EPOCHS = 15\n",
    "    BASE_PATH = '/kaggle/input/'\n",
    "    !pip install torchviz\n",
    "    \n",
    "# running as background job in kaggle\n",
    "elif 'SHLVL' in os.environ:\n",
    "    NUM_EPOCHS = 50\n",
    "    BASE_PATH = '/kaggle/input/'\n",
    "    !pip install torchviz\n",
    "\n",
    "else:\n",
    "    BASE_PATH = '../data/'\n",
    "    NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:06:31.242597Z",
     "iopub.status.busy": "2023-09-19T11:06:31.241840Z",
     "iopub.status.idle": "2023-09-19T11:06:32.526048Z",
     "shell.execute_reply": "2023-09-19T11:06:32.524316Z",
     "shell.execute_reply.started": "2023-09-19T11:06:31.242560Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from collections.abc import Callable\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, locale='')  # for thousands separator via ... print(f'{value:n}')\"\n",
    "import math\n",
    "from itertools import islice\n",
    "from collections.abc import Iterable, Generator\n",
    "from pprint import pprint\n",
    "import pathlib\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "import time\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sklearn.metrics\n",
    "import cv2\n",
    "\n",
    "my_seed = 123\n",
    "random.seed(my_seed)\n",
    "torch.manual_seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Overview of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:06:32.529115Z",
     "iopub.status.busy": "2023-09-19T11:06:32.528191Z",
     "iopub.status.idle": "2023-09-19T11:06:32.537578Z",
     "shell.execute_reply": "2023-09-19T11:06:32.536404Z",
     "shell.execute_reply.started": "2023-09-19T11:06:32.529078Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = pathlib.Path(BASE_PATH + \"plant-seedlings-classification/train/\")\n",
    "for x in path_train.iterdir():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:06:32.540924Z",
     "iopub.status.busy": "2023-09-19T11:06:32.540556Z",
     "iopub.status.idle": "2023-09-19T11:06:32.602262Z",
     "shell.execute_reply": "2023-09-19T11:06:32.601355Z",
     "shell.execute_reply.started": "2023-09-19T11:06:32.540892Z"
    }
   },
   "outputs": [],
   "source": [
    "# collect labels and each label's image paths\n",
    "labels = [d.name for d in path_train.iterdir() if d.is_dir()]\n",
    "\n",
    "labels_arr = []\n",
    "path_arr = []\n",
    "\n",
    "for label in labels:\n",
    "    path_plant_dir = path_train.joinpath(label)\n",
    "    print(f'{label}: {len(list(path_plant_dir.iterdir()))}')\n",
    "    image_paths = list(path_plant_dir.iterdir())\n",
    "    labels_arr.extend([label]*len(image_paths))\n",
    "    path_arr.extend(image_paths)\n",
    "\n",
    "df_meta = pd.DataFrame({'path': path_arr,\n",
    "                         'label': labels_arr})\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:06:32.604192Z",
     "iopub.status.busy": "2023-09-19T11:06:32.603810Z",
     "iopub.status.idle": "2023-09-19T11:06:35.215161Z",
     "shell.execute_reply": "2023-09-19T11:06:35.213948Z",
     "shell.execute_reply.started": "2023-09-19T11:06:32.604142Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5,\n",
    "                         ncols=4,\n",
    "                         figsize=(15,15),\n",
    "                        )\n",
    "\n",
    "for i in range(20):\n",
    "    image_id = random.randrange(len(df_meta))\n",
    "    path = df_meta.iloc[image_id]['path']\n",
    "    example_image = torchvision.io.read_image(str(path))  # [3, e.g. 196, e.g. 196], torch.uint8\n",
    "    example_image = example_image.permute(1, 2, 0)  # [196, 196, 3]\n",
    "\n",
    "    ax = axes[i//4, i%4]\n",
    "    ax.imshow(X=example_image)\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_title(df_meta.iloc[image_id]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:06:35.216974Z",
     "iopub.status.busy": "2023-09-19T11:06:35.216541Z",
     "iopub.status.idle": "2023-09-19T11:07:28.302308Z",
     "shell.execute_reply": "2023-09-19T11:07:28.301240Z",
     "shell.execute_reply.started": "2023-09-19T11:06:35.216938Z"
    }
   },
   "outputs": [],
   "source": [
    "# collect image sizes\n",
    "shapes = np.zeros(shape=(len(df_meta),2), \n",
    "                  dtype=np.uint16)\n",
    "\n",
    "for i, image_path in enumerate(df_meta['path']):\n",
    "    image_path = df_meta.iloc[i]['path']\n",
    "    image = cv2.imread(str(image_path),  # returns np.array of differentshape and dtype uint8\n",
    "                       flags=cv2.IMREAD_COLOR)  # convert to 3 channel BGR (Blue-Green-Red)\n",
    "    \n",
    "    shapes[i] = image.shape[:2]\n",
    "    \n",
    "df_meta['width'] =  shapes[:, 0]\n",
    "df_meta['height'] = shapes[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:07:28.304313Z",
     "iopub.status.busy": "2023-09-19T11:07:28.303801Z",
     "iopub.status.idle": "2023-09-19T11:07:28.327214Z",
     "shell.execute_reply": "2023-09-19T11:07:28.326042Z",
     "shell.execute_reply.started": "2023-09-19T11:07:28.304267Z"
    }
   },
   "outputs": [],
   "source": [
    "df_meta.describe()  # statistical analysis on numerical cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:07:28.329313Z",
     "iopub.status.busy": "2023-09-19T11:07:28.328819Z",
     "iopub.status.idle": "2023-09-19T11:07:28.343824Z",
     "shell.execute_reply": "2023-09-19T11:07:28.342743Z",
     "shell.execute_reply.started": "2023-09-19T11:07:28.329276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Largest Image\n",
    "df_meta[df_meta['width'] == 3457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:07:28.345945Z",
     "iopub.status.busy": "2023-09-19T11:07:28.345492Z",
     "iopub.status.idle": "2023-09-19T11:07:28.359046Z",
     "shell.execute_reply": "2023-09-19T11:07:28.357861Z",
     "shell.execute_reply.started": "2023-09-19T11:07:28.345911Z"
    }
   },
   "outputs": [],
   "source": [
    "# relationship between width and height (how 'unsquare' are our images?)\n",
    "df_meta['aspect_ratio'] = df_meta['width'] / df_meta['height']\n",
    "print(min_ar := min(df_meta['aspect_ratio']))\n",
    "print(max_ar := max(df_meta['aspect_ratio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:07:28.365438Z",
     "iopub.status.busy": "2023-09-19T11:07:28.365065Z",
     "iopub.status.idle": "2023-09-19T11:07:28.381753Z",
     "shell.execute_reply": "2023-09-19T11:07:28.380472Z",
     "shell.execute_reply.started": "2023-09-19T11:07:28.365409Z"
    }
   },
   "outputs": [],
   "source": [
    "df_meta[df_meta['aspect_ratio'] < 0.9 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:07:28.384353Z",
     "iopub.status.busy": "2023-09-19T11:07:28.383873Z",
     "iopub.status.idle": "2023-09-19T11:07:28.397585Z",
     "shell.execute_reply": "2023-09-19T11:07:28.396234Z",
     "shell.execute_reply.started": "2023-09-19T11:07:28.384315Z"
    }
   },
   "outputs": [],
   "source": [
    "df_meta[df_meta['aspect_ratio'] > 1.1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- Total of 4750 images\n",
    "- Minimum size: 49 x 49\n",
    "- Maximum size: 3457 x 3991\n",
    "- Most images are square, some outliers can be accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:07:28.400035Z",
     "iopub.status.busy": "2023-09-19T11:07:28.399648Z",
     "iopub.status.idle": "2023-09-19T11:08:15.597592Z",
     "shell.execute_reply": "2023-09-19T11:08:15.596471Z",
     "shell.execute_reply.started": "2023-09-19T11:07:28.400000Z"
    }
   },
   "outputs": [],
   "source": [
    "SIZE = 70\n",
    "\n",
    "image_list: list[np.array] = []\n",
    "\n",
    "for i, image_path in enumerate(df_meta['path']):\n",
    "    image = cv2.imread(str(image_path),  # returns np.array of differentshape and dtype uint8\n",
    "                   flags=cv2.IMREAD_COLOR)  # convert to 3 channel BGR (Blue-Green-Red)\n",
    "    image_resized = cv2.resize(src=image,  # (70, 70, 3), uint8 0..255\n",
    "                               dsize=(SIZE, SIZE))\n",
    "    image_list.append(image_resized)\n",
    "\n",
    "# merge into one array\n",
    "images = np.asarray(image_list)  # (4750, 70, 70, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:15.599755Z",
     "iopub.status.busy": "2023-09-19T11:08:15.599384Z",
     "iopub.status.idle": "2023-09-19T11:08:15.606849Z",
     "shell.execute_reply": "2023-09-19T11:08:15.605871Z",
     "shell.execute_reply.started": "2023-09-19T11:08:15.599720Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Memory Consumption of resized images: {images.nbytes :n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:15.609152Z",
     "iopub.status.busy": "2023-09-19T11:08:15.608210Z",
     "iopub.status.idle": "2023-09-19T11:08:15.620301Z",
     "shell.execute_reply": "2023-09-19T11:08:15.619223Z",
     "shell.execute_reply.started": "2023-09-19T11:08:15.609115Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_image_to_hsv(image):\n",
    "    # convert from Blue-Green-Red to Hue-Saturation-Value color model\n",
    "    # this makes it easier to represent a color range\n",
    "    image_hsv = cv2.cvtColor(src=image,\n",
    "                             code=cv2.COLOR_BGR2HSV)\n",
    "    return image_hsv\n",
    "    \n",
    "\n",
    "def create_mask_for_plant(image_hsv):\n",
    "    sensitivity = 35\n",
    "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n",
    "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(src=image_hsv, \n",
    "                       lowerb=lower_hsv, \n",
    "                       upperb=upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE,\n",
    "                                       ksize=(11,11))\n",
    "    mask = cv2.morphologyEx(src=mask, \n",
    "                            op=cv2.MORPH_CLOSE, \n",
    "                            kernel=kernel)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def mask_plant(image, mask):\n",
    "    # mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(src1=image, \n",
    "                             src2=image, \n",
    "                             mask=mask)\n",
    "    return output\n",
    "\n",
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(src=image, \n",
    "                                     ksize=(0, 0), \n",
    "                                     sigmaX=3)\n",
    "    image_sharp = cv2.addWeighted(src1=image, \n",
    "                                  alpha=1.5, \n",
    "                                  src2=image_blurred, \n",
    "                                  beta=-0.5, \n",
    "                                  gamma=0)\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Preprocessed Full Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:15.622573Z",
     "iopub.status.busy": "2023-09-19T11:08:15.621633Z",
     "iopub.status.idle": "2023-09-19T11:08:15.637666Z",
     "shell.execute_reply": "2023-09-19T11:08:15.636591Z",
     "shell.execute_reply.started": "2023-09-19T11:08:15.622537Z"
    }
   },
   "outputs": [],
   "source": [
    "random_indexes = [random.randint(0, len(images)) for _ in range(5)]\n",
    "random_images = images[random_indexes]  # (5, 70, 70, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:15.639559Z",
     "iopub.status.busy": "2023-09-19T11:08:15.639116Z",
     "iopub.status.idle": "2023-09-19T11:08:17.212585Z",
     "shell.execute_reply": "2023-09-19T11:08:17.211570Z",
     "shell.execute_reply.started": "2023-09-19T11:08:15.639522Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path = df_meta[df_meta['label'] == 'Small-flowered Cranesbill'].iloc[197]['path']\n",
    "image = cv2.imread(str(image_path), cv2.IMREAD_COLOR)  # (e.g. 760, e.g. 760, 3)  # uint8\n",
    "\n",
    "image_hsv = convert_image_to_hsv(image)\n",
    "image_mask = create_mask_for_plant(image_hsv)\n",
    "image_masked = mask_plant(image, image_mask)\n",
    "image_sharpen = sharpen_image(image_masked)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 20))\n",
    "axs[0].imshow(image)\n",
    "axs[1].imshow(image_hsv)\n",
    "axs[2].imshow(image_mask)\n",
    "axs[3].imshow(image_masked)\n",
    "axs[4].imshow(image_sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Resized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:17.215082Z",
     "iopub.status.busy": "2023-09-19T11:08:17.214086Z",
     "iopub.status.idle": "2023-09-19T11:08:19.128902Z",
     "shell.execute_reply": "2023-09-19T11:08:19.127950Z",
     "shell.execute_reply.started": "2023-09-19T11:08:17.215040Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(random_images), \n",
    "                        ncols=5, \n",
    "                        figsize=(20, 20))\n",
    "\n",
    "for i, image in enumerate(random_images):\n",
    "\n",
    "    image_hsv = convert_image_to_hsv(image)\n",
    "    image_mask = create_mask_for_plant(image_hsv)\n",
    "    image_masked = mask_plant(image, image_mask)\n",
    "    image_sharpened = sharpen_image(image_masked)\n",
    "    \n",
    "    axes[i, 0].imshow(image)\n",
    "    axes[i, 1].imshow(image_hsv)\n",
    "    axes[i, 2].imshow(image_mask)\n",
    "    axes[i, 3].imshow(image_masked)\n",
    "    axes[i, 4].imshow(image_sharpened)\n",
    "\n",
    "# remove the x and y ticks\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "axes[0, 0].set_title('Original', fontsize=30)\n",
    "axes[0, 1].set_title('HSV', fontsize=30)\n",
    "axes[0, 2].set_title('Mask', fontsize=30)\n",
    "axes[0, 3].set_title('Masked', fontsize=30)\n",
    "axes[0, 4].set_title('Sharpened', fontsize=30)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:19.131200Z",
     "iopub.status.busy": "2023-09-19T11:08:19.130518Z",
     "iopub.status.idle": "2023-09-19T11:08:22.913475Z",
     "shell.execute_reply": "2023-09-19T11:08:22.912257Z",
     "shell.execute_reply.started": "2023-09-19T11:08:19.131142Z"
    }
   },
   "outputs": [],
   "source": [
    "masked_image_list = []\n",
    "\n",
    "for image in images:\n",
    "    image_hsv = convert_image_to_hsv(image)\n",
    "    image_mask = create_mask_for_plant(image_hsv)\n",
    "    image_masked = mask_plant(image, image_mask)\n",
    "    image_sharpened = sharpen_image(image_masked)\n",
    "    masked_image_list.append(image_sharpened)\n",
    "\n",
    "masked_images = np.asarray(masked_image_list)  # (4750, 70, 70, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "NN work better with normalized [0.0...1.0] data as input instead of RGB [0...255].\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:22.917289Z",
     "iopub.status.busy": "2023-09-19T11:08:22.916367Z",
     "iopub.status.idle": "2023-09-19T11:08:23.115106Z",
     "shell.execute_reply": "2023-09-19T11:08:23.113932Z",
     "shell.execute_reply.started": "2023-09-19T11:08:22.917235Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized_images = masked_images / 255  # uint8 -> float64\n",
    "\n",
    "# we'll use these images for training\n",
    "x = normalized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels\n",
    "We have an unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:23.117497Z",
     "iopub.status.busy": "2023-09-19T11:08:23.117037Z",
     "iopub.status.idle": "2023-09-19T11:08:23.471873Z",
     "shell.execute_reply": "2023-09-19T11:08:23.470887Z",
     "shell.execute_reply.started": "2023-09-19T11:08:23.117458Z"
    }
   },
   "outputs": [],
   "source": [
    "df_meta['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:31.704130Z",
     "iopub.status.busy": "2023-09-19T11:08:31.703744Z",
     "iopub.status.idle": "2023-09-19T11:08:31.716769Z",
     "shell.execute_reply": "2023-09-19T11:08:31.712601Z",
     "shell.execute_reply.started": "2023-09-19T11:08:31.704099Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(df_meta['label'])  # np.array (4750,), int32, 0..11\n",
    "\n",
    "example = ['Maize']\n",
    "print(f'Example: {example} -> {(enc := label_encoder.transform(example))} -> {label_encoder.inverse_transform(enc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:38.590039Z",
     "iopub.status.busy": "2023-09-19T11:08:38.588890Z",
     "iopub.status.idle": "2023-09-19T11:08:38.767327Z",
     "shell.execute_reply": "2023-09-19T11:08:38.766225Z",
     "shell.execute_reply.started": "2023-09-19T11:08:38.590000Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(x) == len(y)\n",
    "\n",
    "# we need to randomize x and y together\n",
    "randomized_indexes = np.random.permutation(len(x))  # (4750,)\n",
    "x_rnd = x[randomized_indexes]  # still (4750, 70, 70, 3)\n",
    "y_rnd = y[randomized_indexes]  # still (4750,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:38.769678Z",
     "iopub.status.busy": "2023-09-19T11:08:38.769153Z",
     "iopub.status.idle": "2023-09-19T11:08:38.775995Z",
     "shell.execute_reply": "2023-09-19T11:08:38.774868Z",
     "shell.execute_reply.started": "2023-09-19T11:08:38.769640Z"
    }
   },
   "outputs": [],
   "source": [
    "num_train = int(len(x) * 0.85)\n",
    "\n",
    "x_train_arr = x_rnd[:num_train]  # (4037, 70, 70, 3), float64\n",
    "x_val_arr = x_rnd[num_train:]  # (713, 70, 70, 3)\n",
    "\n",
    "y_train_arr = y_rnd[:num_train]  # (4037,)\n",
    "y_val_arr = y_rnd[num_train:]  # (713,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:39.599947Z",
     "iopub.status.busy": "2023-09-19T11:08:39.599198Z",
     "iopub.status.idle": "2023-09-19T11:08:41.623147Z",
     "shell.execute_reply": "2023-09-19T11:08:41.622106Z",
     "shell.execute_reply.started": "2023-09-19T11:08:39.599916Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensorize arrays\n",
    "x_train = torch.tensor(x_train_arr.astype(np.float32)).to(DEVICE)  # [4037, 70, 70, 3], torch.float32\n",
    "x_val = torch.tensor(x_val_arr.astype(np.float32)).to(DEVICE)  # [713, 70, 70, 3], torch.float32\n",
    "\n",
    "y_train = torch.tensor(y_train_arr.astype(np.int64)).to(DEVICE)  # [4037], torch.int64\n",
    "y_val = torch.tensor(y_val_arr.astype(np.int64)).to(DEVICE)  # [713], torch.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:41.626497Z",
     "iopub.status.busy": "2023-09-19T11:08:41.625764Z",
     "iopub.status.idle": "2023-09-19T11:08:41.632295Z",
     "shell.execute_reply": "2023-09-19T11:08:41.631137Z",
     "shell.execute_reply.started": "2023-09-19T11:08:41.626461Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, \n",
    "                                               y_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:41.634418Z",
     "iopub.status.busy": "2023-09-19T11:08:41.633801Z",
     "iopub.status.idle": "2023-09-19T11:08:41.651795Z",
     "shell.execute_reply": "2023-09-19T11:08:41.650716Z",
     "shell.execute_reply.started": "2023-09-19T11:08:41.634384Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 dropout_probability=0.3,\n",
    "                 num_labels=12):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            # (batch_size, 3, 70, 70) -> [batch_size, 32, 70, 70]\n",
    "            torch.nn.Conv2d(in_channels=3,  # Number of channels in the input image\n",
    "                            out_channels=32,  # Number of channels produced by the convolution\n",
    "                            kernel_size=3, #  Size of the convolving kernel\n",
    "                            stride=1,  # Stride of the convolution. Default: 1\n",
    "                            padding=1,  # Padding added to all four sides of the input. Default: 0\n",
    "                           ),\n",
    "            # (element-wise)\n",
    "            torch.nn.ReLU(),\n",
    "            # [batch_size, 32, 70, 70]  - > [batch_size, 32, 35, 35]\n",
    "            torch.nn.MaxPool2d(kernel_size=2, # the size of the window to take a max over\n",
    "                               stride=2,  # the stride of the window. Default value is kernel_size\n",
    "                              ),\n",
    "            # (element-wise)\n",
    "            torch.nn.Dropout(p=dropout_probability,  # probability of an element to be zeroed. Default: 0.5\n",
    "                            ),\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            # [batch_size, 32, 35, 35] --> [batch_size, 64, 35, 35]\n",
    "            torch.nn.Conv2d(in_channels=32,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            # [batch_size, 64, 35, 35] --> [batch_size, 64, 17, 17]\n",
    "            torch.nn.MaxPool2d(kernel_size=2,\n",
    "                               stride=2),\n",
    "            torch.nn.Dropout(p=dropout_probability))\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            # [batch_size, 64, 17, 17] --> [batch_size, 128, 17, 17]\n",
    "            torch.nn.Conv2d(in_channels=64,\n",
    "                            out_channels=128,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            # [batch_size, 128, 17, 17] --> [batch_size, 128, 9, 9]\n",
    "            torch.nn.MaxPool2d(kernel_size=2, \n",
    "                               stride=2, \n",
    "                               padding=1),  # default: 0\n",
    "            torch.nn.Dropout(p=dropout_probability)\n",
    "            )\n",
    "        \n",
    "        # [batch_size, 128, 9, 9] -> [batch_size, 2048]\n",
    "        self.flatten = torch.nn.Flatten()  # for feed-forward \n",
    "\n",
    "# at1 and mat2 shapes cannot be multiplied (16x10368 and 2048x625)\n",
    "        \n",
    "        # [batch_size, 2048] --> [batch_size, 625]\n",
    "        self.fc1 = torch.nn.Linear(in_features=9 * 9 * 128,\n",
    "                                   out_features=625,\n",
    "                                   bias=True)\n",
    "        \n",
    "        # [batch_size, 625] --> [batch_size, 12]\n",
    "        self.fc2 = torch.nn.Linear(in_features=625,\n",
    "                                   out_features=num_labels,\n",
    "                                   bias=True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)  # initialize weights (seems to make no difference)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) \n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x: [batch_size, 70, 70, 3], torch.float32\n",
    "        \n",
    "        # we need the channels at the beginning\n",
    "        # [batch_size, 70, 70, 3] -> [batch_size, 3, 70, 70]\n",
    "        x = x.permute(dims=(0, 3, 1, 2))\n",
    "        \n",
    "        # CNN\n",
    "        output_layer_1 = self.layer1(x)   # [batch_size, 32, 35, 35]\n",
    "        output_layer_2 = self.layer2(output_layer_1)  # [batch_size, 64, 17, 17\n",
    "        output_layer_3 = self.layer3(output_layer_2)  # [batch_size, 128, 9, 9]\n",
    "        flattened = self.flatten(output_layer_3)  # [batch_size, 10368]\n",
    "        \n",
    "        # FC\n",
    "        output_fully_connected_1 = self.fc1(flattened)  # [batch_size, 625]\n",
    "        output_fully_connected_2 = self.fc2(output_fully_connected_1)  # [batch_size, 12]\n",
    "\n",
    "        return output_fully_connected_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:42.435300Z",
     "iopub.status.busy": "2023-09-19T11:08:42.434602Z",
     "iopub.status.idle": "2023-09-19T11:08:44.366307Z",
     "shell.execute_reply": "2023-09-19T11:08:44.365112Z",
     "shell.execute_reply.started": "2023-09-19T11:08:42.435266Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the classifier and make sure it generally works\n",
    "c_temp = CNNClassifier().to(DEVICE)\n",
    "# to visualize with torchviz, we need some input that can pass through the model's forward() method.\n",
    "x_batch, _ = next(iter(train_loader)) \n",
    "predictions = c_temp(x_batch)\n",
    "make_dot(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:44.369040Z",
     "iopub.status.busy": "2023-09-19T11:08:44.368490Z",
     "iopub.status.idle": "2023-09-19T11:08:44.483009Z",
     "shell.execute_reply": "2023-09-19T11:08:44.481961Z",
     "shell.execute_reply.started": "2023-09-19T11:08:44.369006Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "classifier = CNNClassifier().to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(),\n",
    "                             lr = LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  # reduce learning rate when model stops improving on validation dataset \n",
    "                                                       mode='min', \n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:44.485151Z",
     "iopub.status.busy": "2023-09-19T11:08:44.484754Z",
     "iopub.status.idle": "2023-09-19T11:08:44.493521Z",
     "shell.execute_reply": "2023-09-19T11:08:44.492216Z",
     "shell.execute_reply.started": "2023-09-19T11:08:44.485117Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(classifier: CNNClassifier, \n",
    "                    loss_fn: Callable,\n",
    "                    x: torch.Tensor, \n",
    "                    y: torch.Tensor\n",
    "                   )->tuple[float, float, float]:\n",
    "    \n",
    "        y_pred_logits = classifier(x)\n",
    "        loss = loss_fn(y_pred_logits, y).item()\n",
    "    \n",
    "        y_pred = y_pred_logits.argmax(dim=1)\n",
    "        correct = (y_pred == y).type(torch.FloatTensor)\n",
    "        accuracy = correct.mean().item()\n",
    "\n",
    "        f1_score = sklearn.metrics.f1_score(y_true=y.cpu(), \n",
    "                                            y_pred=y_pred.cpu(),\n",
    "                                            average='micro')  # multi-class problem\n",
    "        \n",
    "        return loss, accuracy, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:08:44.969456Z",
     "iopub.status.busy": "2023-09-19T11:08:44.968686Z",
     "iopub.status.idle": "2023-09-19T11:09:11.950801Z",
     "shell.execute_reply": "2023-09-19T11:09:11.949700Z",
     "shell.execute_reply.started": "2023-09-19T11:08:44.969416Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(columns=['loss_train', 'accuracy_train', 'f1_train', \n",
    "                                   'loss_val', 'accuracy_val', 'f1_val'],\n",
    "                          index=range(NUM_EPOCHS),\n",
    "                          dtype=float)\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "    for batch, (x_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "        # x_train_batch: [batch_size, 70, 70, 3] torch.float32\n",
    "        # y_train_batch: [batch_size] torch.int64\n",
    "\n",
    "        # x_train_batch = x_train_batch.to(DEVICE)\n",
    "        # y_train_batch = y_train_batch.to(DEVICE)\n",
    "\n",
    "        # switch to training mode mode (we might have been in evaluation mode)\n",
    "        classifier.train()\n",
    "\n",
    "        pred_train_batch_logits = classifier(x_train_batch)  # [batch_size, 12], float32\n",
    "\n",
    "        # clear existing gradients from previous batch\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(pred_train_batch_logits,\n",
    "                       y_train_batch)  # [], .item() is e.g. 2.291177988052368\n",
    "\n",
    "        # compute gradients (backpropagation), then apply gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # after each epoch, switch to evaluation mode, then evaluate without computing gradients\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_train, accuracy_train, f1_score_train = compute_metrics(classifier, loss_fn, x_train, y_train)\n",
    "        loss_val, accuracy_val, f1_score_val = compute_metrics(classifier, loss_fn, x_val, y_val)\n",
    "\n",
    "        df_metrics.iloc[epoch] = [loss_train, accuracy_train, f1_score_train,\n",
    "                                  loss_val, accuracy_val, f1_score_val]\n",
    "        \n",
    "    scheduler.step(loss_val)\n",
    "    print(f'Accuracy Validation after epoch {epoch}: {accuracy_val :.4f}  '\n",
    "          f'(Train: {accuracy_train :.4f}) '\n",
    "          f'LR = {optimizer.param_groups[0][\"lr\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:09:11.954131Z",
     "iopub.status.busy": "2023-09-19T11:09:11.953349Z",
     "iopub.status.idle": "2023-09-19T11:09:12.050703Z",
     "shell.execute_reply": "2023-09-19T11:09:12.049658Z",
     "shell.execute_reply.started": "2023-09-19T11:09:11.954093Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:09:15.384687Z",
     "iopub.status.busy": "2023-09-19T11:09:15.384315Z",
     "iopub.status.idle": "2023-09-19T11:09:16.515752Z",
     "shell.execute_reply": "2023-09-19T11:09:16.514602Z",
     "shell.execute_reply.started": "2023-09-19T11:09:15.384657Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = range(NUM_EPOCHS)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, _)) = plt.subplots(nrows=2,\n",
    "                                       ncols=2,\n",
    "                                       figsize=(15,5),\n",
    "                                          sharex=True)\n",
    "\n",
    "# Plot and label the training and val loss values\n",
    "ax1.plot(epochs, df_metrics['loss_train'], label='Training Loss')\n",
    "ax1.plot(epochs, df_metrics['loss_val'], label='val Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "# ... Accuracy\n",
    "ax2.plot(epochs, df_metrics['accuracy_train'], label='Training Accuracy')\n",
    "ax2.plot(epochs, df_metrics['accuracy_val'], label='val Accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "# ... F1-Score\n",
    "ax3.plot(epochs, df_metrics['f1_train'], label='Training F1-Score')\n",
    "ax3.plot(epochs, df_metrics['f1_val'], label='val F1-Score')\n",
    "ax3.set_ylabel('F1-Score')\n",
    "ax3.legend(loc='best')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_xticks(np.arange(0, \n",
    "                         NUM_EPOCHS))\n",
    "\n",
    "plt.suptitle('Training and Validation Metrics')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(0, \n",
    "                     NUM_EPOCHS))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:14:15.535070Z",
     "iopub.status.busy": "2023-09-19T11:14:15.534653Z",
     "iopub.status.idle": "2023-09-19T11:14:20.188415Z",
     "shell.execute_reply": "2023-09-19T11:14:20.187231Z",
     "shell.execute_reply.started": "2023-09-19T11:14:15.535036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess test data\n",
    "path_test = pathlib.Path(BASE_PATH + \"plant-seedlings-classification/test/\")\n",
    "image_list_test = []\n",
    "filenames = []\n",
    "\n",
    "for path in path_test.iterdir():\n",
    "    image = cv2.imread(str(path),\n",
    "                       flags=cv2.IMREAD_COLOR)\n",
    "    image_resized = cv2.resize(src=image,\n",
    "                               dsize=(SIZE, SIZE))\n",
    "    image_hsv = convert_image_to_hsv(image_resized)\n",
    "    image_mask = create_mask_for_plant(image_hsv)\n",
    "    image_masked = mask_plant(image_resized, image_mask)\n",
    "    image_sharpened = sharpen_image(image_masked)\n",
    "    \n",
    "    image_list_test.append(image_sharpened)\n",
    "    \n",
    "    filenames.append(path.name)\n",
    "\n",
    "images_test = np.asarray(image_list_test)  # (794, 70, 70, 3)\n",
    "\n",
    "normalized_images_test = images_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:14:22.189575Z",
     "iopub.status.busy": "2023-09-19T11:14:22.189135Z",
     "iopub.status.idle": "2023-09-19T11:14:22.344843Z",
     "shell.execute_reply": "2023-09-19T11:14:22.343729Z",
     "shell.execute_reply.started": "2023-09-19T11:14:22.189543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict the labels\n",
    "\n",
    "x_test = torch.tensor(normalized_images_test.astype(np.float32)).to(DEVICE)  # [794, 70, 70, 3], torch.float32\n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_logits = classifier(x_test)  # [794, 12], torch.float32\n",
    "    y_pred = y_pred_logits.argmax(dim=1)  # [794], torch.int64\n",
    "    predicted_labels = y_pred.cpu().numpy()  # np.array (794,), int64\n",
    "    \n",
    "predicted_plants = label_encoder.inverse_transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:14:25.637848Z",
     "iopub.status.busy": "2023-09-19T11:14:25.637093Z",
     "iopub.status.idle": "2023-09-19T11:14:25.982123Z",
     "shell.execute_reply": "2023-09-19T11:14:25.981127Z",
     "shell.execute_reply.started": "2023-09-19T11:14:25.637807Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(predicted_plants).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:14:26.422472Z",
     "iopub.status.busy": "2023-09-19T11:14:26.421054Z",
     "iopub.status.idle": "2023-09-19T11:14:26.431740Z",
     "shell.execute_reply": "2023-09-19T11:14:26.430575Z",
     "shell.execute_reply.started": "2023-09-19T11:14:26.422429Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is how the submission file must look like\n",
    "with open(BASE_PATH + \"plant-seedlings-classification/sample_submission.csv\")as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())\n",
    "    print(f.readline())\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-19T11:15:53.986062Z",
     "iopub.status.busy": "2023-09-19T11:15:53.985660Z",
     "iopub.status.idle": "2023-09-19T11:15:53.999405Z",
     "shell.execute_reply": "2023-09-19T11:15:53.998320Z",
     "shell.execute_reply.started": "2023-09-19T11:15:53.986033Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'file': filenames,\n",
    "                              'species': predicted_plants})\n",
    "df_submission.to_csv('submission.csv',\n",
    "                      index=False)\n",
    "\n",
    "# make sure it has the correct format...\n",
    "with open(\"submission.csv\")as f:\n",
    "    print(f.readline())\n",
    "    print(f.readline())\n",
    "    print(f.readline())\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
