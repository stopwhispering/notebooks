{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63537188-e57e-40c1-a82c-844be261375c"
   },
   "source": [
    "# MNIST Digits Classification - Simple PyTorchðŸ”¥CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc8f4523-57da-4bf5-8a6a-65f2b563eda3"
   },
   "source": [
    "Subject: Building a CNN Classificator with PyTorch to classify hand-written digits.\n",
    "\n",
    "Data: MNIST (handwritten digits) via torchvision\n",
    "\n",
    "Procedure:\n",
    "- Previewing images from dataset with pyplot's imshow()\n",
    "- Neural network with torch.nn.module, torch.nn.Sequential, torch.nn.Conv2d, torch.nn.ReLU, torch.nn.MaxPool2d, torch.nn.Dropout, torch.nn.Linear, and torch.nn.init.xavier_uniform_\n",
    "- Visualizing model with torchviz' make_dot()\n",
    "- Training with nn.CrossEntropyLoss and torch.optim.Adam optimizer\n",
    "- Visualization Loss and Accuracy with pyplot\n",
    "- Visualization of the CNN Layers with pyplot's imshow()\n",
    "- Good results\n",
    "\n",
    "Others:\n",
    "- Compatible with Google Colab and Kaggle as runtime\n",
    "- CUDA support\n",
    "\n",
    "Sources used:\n",
    "- https://machinelearningknowledge.ai/pytorch-conv2d-explained-with-examples/\n",
    "- Probably some more, but this is an old Notebook and I forgot the sources. Please let me know if I copied your code and I will mention it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a8ae951-ac9f-49f6-95a9-5278bb3b1d7f"
   },
   "source": [
    "## Bootstrap and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:34:38.599422Z",
     "iopub.status.busy": "2023-09-18T17:34:38.599161Z",
     "iopub.status.idle": "2023-09-18T17:34:58.274404Z",
     "shell.execute_reply": "2023-09-18T17:34:58.273003Z",
     "shell.execute_reply.started": "2023-09-18T17:34:38.599398Z"
    },
    "id": "a2707413-c690-47d9-8653-faaa579805ad",
    "outputId": "74f54c7f-58ec-40e7-d543-5cb2e74224aa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Running on {DEVICE}')\n",
    "\n",
    "# running in google colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    NUM_EPOCHS = 50\n",
    "    !pip install torchviz\n",
    "    BASE_PATH = './drive/MyDrive/Colab/data/'\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# running interactively in kaggle\n",
    "elif get_ipython().config.IPKernelApp.connection_file.startswith('/root/.local/share'):\n",
    "    NUM_EPOCHS = 5\n",
    "    BASE_PATH = '/kaggle/input/'\n",
    "    !pip install torchviz\n",
    "    \n",
    "# running as background job in kaggle\n",
    "elif 'SHLVL' in os.environ:\n",
    "    NUM_EPOCHS = 50\n",
    "    BASE_PATH = '/kaggle/input/'\n",
    "    !pip install torchviz\n",
    "\n",
    "else:\n",
    "    BASE_PATH = '../data/'\n",
    "    NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:34:58.278939Z",
     "iopub.status.busy": "2023-09-18T17:34:58.278307Z",
     "iopub.status.idle": "2023-09-18T17:34:59.720305Z",
     "shell.execute_reply": "2023-09-18T17:34:59.719357Z",
     "shell.execute_reply.started": "2023-09-18T17:34:58.278909Z"
    },
    "id": "0d009e82-fd22-47ba-88db-405d5e6736f6",
    "outputId": "99f83002-7c34-4024-9a98-a00db2a23b34"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from collections.abc import Callable\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, locale='')  # for thousands separator via ... print(f'{value:n}')\"\n",
    "import math\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "import time\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sklearn.metrics\n",
    "\n",
    "my_seed = 123\n",
    "random.seed(my_seed)\n",
    "torch.manual_seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df5a0ac4-29c4-4c40-8fee-33f53780f076"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:34:59.722367Z",
     "iopub.status.busy": "2023-09-18T17:34:59.721852Z",
     "iopub.status.idle": "2023-09-18T17:35:05.826690Z",
     "shell.execute_reply": "2023-09-18T17:35:05.824729Z",
     "shell.execute_reply.started": "2023-09-18T17:34:59.722334Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = BASE_PATH + 'digit-recognizer/train.csv'\n",
    "path_test = BASE_PATH + 'digit-recognizer/test.csv'\n",
    "\n",
    "df_train_source = pd.read_csv(path_train)\n",
    "df_test = pd.read_csv(path_test)\n",
    "\n",
    "print(df_train_source.columns)\n",
    "print(df_test.columns)\n",
    "\n",
    "print(df_train_source.shape)\n",
    "print(df_test.shape)\n",
    "assert 'label' in df_train_source\n",
    "assert 'label' not in df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:05.830219Z",
     "iopub.status.busy": "2023-09-18T17:35:05.829711Z",
     "iopub.status.idle": "2023-09-18T17:35:06.003714Z",
     "shell.execute_reply": "2023-09-18T17:35:06.002652Z",
     "shell.execute_reply.started": "2023-09-18T17:35:05.830183Z"
    }
   },
   "outputs": [],
   "source": [
    "# split train into train and validation\n",
    "df_train_randomized = df_train_source.sample(frac=1)\n",
    "NUM_VAL = int(len(df_train_randomized) * 0.15)\n",
    "\n",
    "df_train_with_label = df_train_randomized[:-NUM_VAL]  # (35700, 785)\n",
    "df_val_with_label = df_train_randomized[-NUM_VAL:]  # (6300, 785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:06.005616Z",
     "iopub.status.busy": "2023-09-18T17:35:06.005255Z",
     "iopub.status.idle": "2023-09-18T17:35:06.012959Z",
     "shell.execute_reply": "2023-09-18T17:35:06.011457Z",
     "shell.execute_reply.started": "2023-09-18T17:35:06.005584Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train_with_label.iloc[:,1:]  # (35700, 784)\n",
    "df_val = df_val_with_label.iloc[:,1:]  # (6300, 784)\n",
    "\n",
    "ser_y_train = df_train_with_label.iloc[:,0]  # (35700,)\n",
    "ser_y_val = df_val_with_label.iloc[:,0]  # (6300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:06.015506Z",
     "iopub.status.busy": "2023-09-18T17:35:06.014593Z",
     "iopub.status.idle": "2023-09-18T17:35:06.043904Z",
     "shell.execute_reply": "2023-09-18T17:35:06.043000Z",
     "shell.execute_reply.started": "2023-09-18T17:35:06.015471Z"
    }
   },
   "outputs": [],
   "source": [
    "assert all(df_train.columns == df_val.columns)\n",
    "assert all(df_train.columns == df_test.columns)\n",
    "\n",
    "# no nan treatment required\n",
    "assert df_train.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T10:49:41.388714Z",
     "iopub.status.busy": "2023-09-18T10:49:41.388271Z",
     "iopub.status.idle": "2023-09-18T10:49:41.415270Z",
     "shell.execute_reply": "2023-09-18T10:49:41.414290Z",
     "shell.execute_reply.started": "2023-09-18T10:49:41.388678Z"
    }
   },
   "source": [
    "## Tensorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:06.045795Z",
     "iopub.status.busy": "2023-09-18T17:35:06.045455Z",
     "iopub.status.idle": "2023-09-18T17:35:06.212318Z",
     "shell.execute_reply": "2023-09-18T17:35:06.211154Z",
     "shell.execute_reply.started": "2023-09-18T17:35:06.045764Z"
    }
   },
   "outputs": [],
   "source": [
    "# from flat 784 (1..255) to 28*28 pixels with 1 normalized channel (0.0..1.0)\n",
    "def reshape(df: pd.DataFrame) -> np.array:  # df: (n, 784), all int64\n",
    "    df = df.values.reshape(-1, 28, 28)  # (n, 28, 28), int64\n",
    "    df = df.astype(np.float32)  # (n, 28, 28), float32\n",
    "    # the pixels have 256 values (0.0..255.0), therefore we normalize to (0.0..1.0)\n",
    "    df = df / 255.0\n",
    "    return df\n",
    "    \n",
    "    \n",
    "arr_train = reshape(df_train)  # np.array (35700, 28, 28), float32\n",
    "arr_val = reshape(df_val)  # np.array (6300, 28, 28)\n",
    "arr_test = reshape(df_test)  # np.array (28000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:06.214486Z",
     "iopub.status.busy": "2023-09-18T17:35:06.213950Z",
     "iopub.status.idle": "2023-09-18T17:35:09.109860Z",
     "shell.execute_reply": "2023-09-18T17:35:09.108858Z",
     "shell.execute_reply.started": "2023-09-18T17:35:06.214444Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensorize\n",
    "train = torch.tensor(arr_train).to(DEVICE)  # torch.float32\n",
    "val = torch.tensor(arr_val).to(DEVICE)\n",
    "test = torch.tensor(arr_test).to(DEVICE)\n",
    "\n",
    "y_train = torch.tensor(ser_y_train.values).to(DEVICE)  # [35700], torch.int64\n",
    "y_val = torch.tensor(ser_y_val.values).to(DEVICE)  # [6300], torch.int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:09.111845Z",
     "iopub.status.busy": "2023-09-18T17:35:09.111425Z",
     "iopub.status.idle": "2023-09-18T17:35:09.118082Z",
     "shell.execute_reply": "2023-09-18T17:35:09.117133Z",
     "shell.execute_reply.started": "2023-09-18T17:35:09.111810Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:09.124944Z",
     "iopub.status.busy": "2023-09-18T17:35:09.123861Z",
     "iopub.status.idle": "2023-09-18T17:35:09.131935Z",
     "shell.execute_reply": "2023-09-18T17:35:09.131001Z",
     "shell.execute_reply.started": "2023-09-18T17:35:09.124856Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(dataset=dataset_train,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:09.134161Z",
     "iopub.status.busy": "2023-09-18T17:35:09.133546Z",
     "iopub.status.idle": "2023-09-18T17:35:09.905981Z",
     "shell.execute_reply": "2023-09-18T17:35:09.904922Z",
     "shell.execute_reply.started": "2023-09-18T17:35:09.134089Z"
    }
   },
   "outputs": [],
   "source": [
    "# preview first ten images\n",
    "def print_ten_numbers(x: torch.Tensor, \n",
    "                      y: torch.Tensor):\n",
    "    fig = plt.figure(figsize=(25, 10))  # (width, height) in inches\n",
    "    for i in range(10):\n",
    "        ax = fig.add_subplot(1,  # nrows\n",
    "                             10,  # ncols\n",
    "                             i+1, # index (1-based)\n",
    "                             xticks=[],\n",
    "                             yticks=[])\n",
    "        image = x[i]  # [28, 28]\n",
    "        label = y[i].item()  # int\n",
    "        ax.imshow(X=image.squeeze().cpu(),\n",
    "                  cmap='gray')\n",
    "        ax.set_title(f\"{label}\")\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))   # x_batch: [128, 28, 28] torch.float32, y_batch: [128] torch.int64\n",
    "print_ten_numbers(x=x_batch, y=y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ab5f6f3-4749-478c-b511-77b07a97a6ff"
   },
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:09.907818Z",
     "iopub.status.busy": "2023-09-18T17:35:09.907490Z",
     "iopub.status.idle": "2023-09-18T17:35:09.924201Z",
     "shell.execute_reply": "2023-09-18T17:35:09.923128Z",
     "shell.execute_reply.started": "2023-09-18T17:35:09.907791Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(torch.nn.Module):\n",
    "    # https://machinelearningknowledge.ai/pytorch-conv2d-explained-with-examples/\n",
    "\n",
    "    def __init__(self, dropout_probability=0.3):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        # add dummy input channel: [batch_size, 28, 28] -> [batch_size, 1, 28, 28]\n",
    "        self.unflatten = torch.nn.Unflatten(dim=1, unflattened_size=(1,28))\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            # (batch_size, 1, 28, 28) -> (batch_size, 32, 28, 28)\n",
    "            torch.nn.Conv2d(in_channels=1,  # Number of channels in the input image\n",
    "                            out_channels=32,  # Number of channels produced by the convolution\n",
    "                            kernel_size=3, #  Size of the convolving kernel\n",
    "                            stride=1,  # Stride of the convolution. Default: 1\n",
    "                            padding=1,  # Padding added to all four sides of the input. Default: 0\n",
    "                           ),\n",
    "            # (element-wise)\n",
    "            torch.nn.ReLU(),\n",
    "            # (batch_size, 32, 28, 28)  - > (batch_size, 32, 14, 14)\n",
    "            torch.nn.MaxPool2d(kernel_size=2, # the size of the window to take a max over\n",
    "                               stride=2,  # the stride of the window. Default value is kernel_size\n",
    "                              ),\n",
    "            # (element-wise)\n",
    "            torch.nn.Dropout(p=dropout_probability,  # probability of an element to be zeroed. Default: 0.5\n",
    "                            ),\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            # (batch_size, 32, 14, 14) --> (batch_size, 64, 14, 14)\n",
    "            torch.nn.Conv2d(in_channels=32,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            # (batch_size, 64, 14, 14) --> (batch_size, 64, 7, 7)\n",
    "            torch.nn.MaxPool2d(kernel_size=2,\n",
    "                               stride=2),\n",
    "            torch.nn.Dropout(p=dropout_probability))\n",
    "\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            # (batch_size, 64, 7, 7) --> (batch_size, 128, 7, 7)\n",
    "            torch.nn.Conv2d(in_channels=64,\n",
    "                            out_channels=128,\n",
    "                            kernel_size=3,\n",
    "                            stride=1,\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            # (batch_size, 128, 7, 7) --> (batch_size, 128, 4, 4)\n",
    "            torch.nn.MaxPool2d(kernel_size=2, \n",
    "                               stride=2, \n",
    "                               padding=1),  # default: 0\n",
    "            torch.nn.Dropout(p=dropout_probability)\n",
    "            )\n",
    "        \n",
    "        # [batch_size, 128, 4, 4] -> [batch_size, 2048]\n",
    "        self.flatten = torch.nn.Flatten()  # for feed-forward \n",
    "\n",
    "        # [batch_size, 2048] --> [batch_size, 625]\n",
    "        self.fc1 = torch.nn.Linear(in_features=4 * 4 * 128,\n",
    "                                   out_features=625,\n",
    "                                   bias=True)\n",
    "        \n",
    "        # [batch_size, 625] --> [batch_size, 10]\n",
    "        self.fc2 = torch.nn.Linear(in_features=625,\n",
    "                                   out_features=10,\n",
    "                                   bias=True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)  # initialize weights (seems to make no difference)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight) \n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x: [batch_size, 28, 28]\n",
    "        \n",
    "        # CNN\n",
    "        x_unflattened = self.unflatten(x)\n",
    "        output_layer_1 = self.layer1(x_unflattened)  # [batch_size, 32, 14, 14]\n",
    "        output_layer_2 = self.layer2(output_layer_1)  # [batch_size, 64, 7, 7]\n",
    "        output_layer_3 = self.layer3(output_layer_2)  # [batch_size, 128, 4, 4]\n",
    "        flattened = self.flatten(output_layer_3)  # flattened to[batch_size, 2048]\n",
    "        \n",
    "        # FC\n",
    "        output_fully_connected_1 = self.fc1(flattened)  # [batch_size, 625]\n",
    "        output_fully_connected_2 = self.fc2(output_fully_connected_1)  # [batch_size, 10]\n",
    "\n",
    "        return output_fully_connected_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:09.926177Z",
     "iopub.status.busy": "2023-09-18T17:35:09.925719Z",
     "iopub.status.idle": "2023-09-18T17:35:14.774112Z",
     "shell.execute_reply": "2023-09-18T17:35:14.773087Z",
     "shell.execute_reply.started": "2023-09-18T17:35:09.926144Z"
    },
    "id": "2903f806-70e6-44ca-90bc-f83486d89692",
    "outputId": "5811b562-5fdc-4075-e4dd-a1ce20b9a44a"
   },
   "outputs": [],
   "source": [
    "# visualize the classifier\n",
    "c_temp = CNNClassifier().to(DEVICE)\n",
    "# to visualize with torchviz, we need some input that can pass through the model's forward() method.\n",
    "predictions = c_temp(x_batch)\n",
    "make_dot(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8226b58-ecfd-4803-b2fc-596d78f72817"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:14.776325Z",
     "iopub.status.busy": "2023-09-18T17:35:14.775866Z",
     "iopub.status.idle": "2023-09-18T17:35:14.811415Z",
     "shell.execute_reply": "2023-09-18T17:35:14.810369Z",
     "shell.execute_reply.started": "2023-09-18T17:35:14.776290Z"
    },
    "id": "6846e1a8-e39e-43cd-97e9-3c5415a531f3"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "classifier = CNNClassifier().to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(),\n",
    "                             lr = LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  # reduce learning rate when model stops improving on validation dataset \n",
    "                                                       mode='min', \n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:14.813561Z",
     "iopub.status.busy": "2023-09-18T17:35:14.812880Z",
     "iopub.status.idle": "2023-09-18T17:35:14.821191Z",
     "shell.execute_reply": "2023-09-18T17:35:14.820149Z",
     "shell.execute_reply.started": "2023-09-18T17:35:14.813508Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(classifier: CNNClassifier, \n",
    "                    loss_fn: Callable,\n",
    "                    x: torch.Tensor, \n",
    "                    y: torch.Tensor\n",
    "                   )->tuple[float, float, float]:\n",
    "    \n",
    "        y_pred_logits = classifier(x)\n",
    "        loss = loss_fn(y_pred_logits, y).item()\n",
    "    \n",
    "        y_pred = y_pred_logits.argmax(dim=1)\n",
    "        correct = (y_pred == y).type(torch.FloatTensor)\n",
    "        accuracy = correct.mean().item()\n",
    "\n",
    "        f1_score = sklearn.metrics.f1_score(y_true=y.cpu(), \n",
    "                                            y_pred=y_pred.cpu(),\n",
    "                                            average='micro')  # multi-class problem\n",
    "        \n",
    "        return loss, accuracy, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:14.824021Z",
     "iopub.status.busy": "2023-09-18T17:35:14.823128Z",
     "iopub.status.idle": "2023-09-18T17:35:24.446329Z",
     "shell.execute_reply": "2023-09-18T17:35:24.445026Z",
     "shell.execute_reply.started": "2023-09-18T17:35:14.823972Z"
    },
    "id": "42479bc0-e113-4984-8de1-c48b69c4428b",
    "outputId": "d0a60f95-3cdf-48d9-c783-66a17f86fc0a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(columns=['loss_train', 'accuracy_train', 'f1_train', \n",
    "                                   'loss_val', 'accuracy_val', 'f1_val'],\n",
    "                          index=range(NUM_EPOCHS))\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "    for batch, (x_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "        # x_train_batch: [batch_size, 28, 28] torch.float32\n",
    "        # y_train_batch: [batch_size] torch.int64\n",
    "\n",
    "        x_train_batch = x_train_batch.to(DEVICE)\n",
    "        y_train_batch = y_train_batch.to(DEVICE)\n",
    "\n",
    "        # switch to training mode mode (we might have been in evaluation mode)\n",
    "        classifier.train()\n",
    "\n",
    "        pred_train_batch = classifier(x_train_batch)  # [batch_size, 10]\n",
    "\n",
    "        # clear existing gradients from previous batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(pred_train_batch,\n",
    "                       y_train_batch)  # [], .item() is e.g. 2.291177988052368\n",
    "\n",
    "        # compute gradients (backpropagation), then apply gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # after each epoch, switch to evaluation mode, then evaluate without computing gradients\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_train, accuracy_train, f1_score_train = compute_metrics(classifier, loss_fn, train, y_train)\n",
    "        # val: [6300, 28, 28], torch.float32\n",
    "        loss_val, accuracy_val, f1_score_val = compute_metrics(classifier, loss_fn, val, y_val)\n",
    "\n",
    "        df_metrics.iloc[epoch] = [loss_train, accuracy_train, f1_score_train,\n",
    "                                  loss_val, accuracy_val, f1_score_val]\n",
    "        \n",
    "    scheduler.step(loss_val)\n",
    "    print(f'Accuracy Validation after epoch {epoch}: {accuracy_val :.4f}  '\n",
    "          f'(Train: {accuracy_train :.4f}) '\n",
    "          f'LR = {optimizer.param_groups[0][\"lr\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:24.449081Z",
     "iopub.status.busy": "2023-09-18T17:35:24.448004Z",
     "iopub.status.idle": "2023-09-18T17:35:24.456439Z",
     "shell.execute_reply": "2023-09-18T17:35:24.455229Z",
     "shell.execute_reply.started": "2023-09-18T17:35:24.449045Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:24.459307Z",
     "iopub.status.busy": "2023-09-18T17:35:24.458471Z",
     "iopub.status.idle": "2023-09-18T17:35:24.477894Z",
     "shell.execute_reply": "2023-09-18T17:35:24.476399Z",
     "shell.execute_reply.started": "2023-09-18T17:35:24.459272Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_metrics.shape)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:24.480036Z",
     "iopub.status.busy": "2023-09-18T17:35:24.479381Z",
     "iopub.status.idle": "2023-09-18T17:35:25.199722Z",
     "shell.execute_reply": "2023-09-18T17:35:25.198655Z",
     "shell.execute_reply.started": "2023-09-18T17:35:24.480000Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = range(NUM_EPOCHS)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, _)) = plt.subplots(nrows=2,\n",
    "                                       ncols=2,\n",
    "                                       figsize=(15,5),\n",
    "                                          sharex=True)\n",
    "\n",
    "# Plot and label the training and val loss values\n",
    "ax1.plot(epochs, df_metrics['loss_train'], label='Training Loss')\n",
    "ax1.plot(epochs, df_metrics['loss_val'], label='val Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend(loc='best')\n",
    "\n",
    "# ... Accuracy\n",
    "ax2.plot(epochs, df_metrics['accuracy_train'], label='Training Accuracy')\n",
    "ax2.plot(epochs, df_metrics['accuracy_val'], label='val Accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "# ... F1-Score\n",
    "ax3.plot(epochs, df_metrics['f1_train'], label='Training F1-Score')\n",
    "ax3.plot(epochs, df_metrics['f1_val'], label='val F1-Score')\n",
    "ax3.set_ylabel('F1-Score')\n",
    "ax3.legend(loc='best')\n",
    "ax3.set_xlabel('Epochs')\n",
    "ax3.set_xticks(np.arange(0, \n",
    "                         NUM_EPOCHS))\n",
    "\n",
    "plt.suptitle('Training and Validation Metrics')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(0, \n",
    "                     NUM_EPOCHS))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:25.201112Z",
     "iopub.status.busy": "2023-09-18T17:35:25.200766Z",
     "iopub.status.idle": "2023-09-18T17:35:25.272425Z",
     "shell.execute_reply": "2023-09-18T17:35:25.271319Z",
     "shell.execute_reply.started": "2023-09-18T17:35:25.201080Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's have a look at some of the misclassified images from the validation dataset\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_logits = classifier(val)\n",
    "    y_pred = y_pred_logits.argmax(dim=1)\n",
    "    correct = (y_pred == y_val).type(torch.FloatTensor)  # [6300] with either 1.0 or 0.0\n",
    "   \n",
    "ser_correct = pd.Series(correct)\n",
    "print(ser_correct.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:25.274391Z",
     "iopub.status.busy": "2023-09-18T17:35:25.273922Z",
     "iopub.status.idle": "2023-09-18T17:35:25.285407Z",
     "shell.execute_reply": "2023-09-18T17:35:25.284178Z",
     "shell.execute_reply.started": "2023-09-18T17:35:25.274358Z"
    }
   },
   "outputs": [],
   "source": [
    "bad_indexes = ser_correct[ser_correct == 0.0].index.to_list()\n",
    "\n",
    "val_misclassified = val[bad_indexes]  # [69, 28, 28]\n",
    "y_val_misclassified = y_val[bad_indexes]\n",
    "y_pred_misclassified = y_pred[bad_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:25.287559Z",
     "iopub.status.busy": "2023-09-18T17:35:25.286982Z",
     "iopub.status.idle": "2023-09-18T17:35:29.997787Z",
     "shell.execute_reply": "2023-09-18T17:35:29.996877Z",
     "shell.execute_reply.started": "2023-09-18T17:35:25.287505Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=math.ceil(len(val_misclassified) / 10),  # axes: np.array of shape (7, 10)\n",
    "                         ncols=10,\n",
    "                         figsize=(15,15),\n",
    "                        )\n",
    "\n",
    "for i in range(len(val_misclassified)):\n",
    "    image = val_misclassified[i]\n",
    "    y = y_val_misclassified[i].item()\n",
    "    pred = y_pred_misclassified[i].item()\n",
    "    \n",
    "    ax = axes[i//10, i%10]\n",
    "    \n",
    "    ax.imshow(X=image.squeeze(dim=0).cpu(),\n",
    "              cmap='gray')\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_title(f\"âœ“{y} / âš  {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:30.000163Z",
     "iopub.status.busy": "2023-09-18T17:35:29.999470Z",
     "iopub.status.idle": "2023-09-18T17:35:30.295421Z",
     "shell.execute_reply": "2023-09-18T17:35:30.293775Z",
     "shell.execute_reply.started": "2023-09-18T17:35:30.000130Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_logits = classifier(test)  # [28000, 10], torch.float32\n",
    "    y_pred = y_pred_logits.argmax(dim=1)  # [28000], torch.int64\n",
    "    \n",
    "    predicted_labels = y_pred.cpu().numpy()  # np.array (28000,), int64\n",
    "\n",
    "print(predicted_labels)\n",
    "print(pd.Series(predicted_labels).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:30.297469Z",
     "iopub.status.busy": "2023-09-18T17:35:30.297093Z",
     "iopub.status.idle": "2023-09-18T17:35:30.309616Z",
     "shell.execute_reply": "2023-09-18T17:35:30.308191Z",
     "shell.execute_reply.started": "2023-09-18T17:35:30.297437Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({'ImageId': range(1, len(test)+1),\n",
    "                        'Label': predicted_labels})\n",
    "df_pred['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:30.311686Z",
     "iopub.status.busy": "2023-09-18T17:35:30.310833Z",
     "iopub.status.idle": "2023-09-18T17:35:30.379494Z",
     "shell.execute_reply": "2023-09-18T17:35:30.378360Z",
     "shell.execute_reply.started": "2023-09-18T17:35:30.311651Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred.to_csv('submission.csv',\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86ef8fc9-4c4f-481f-ae7d-27cada9d49ef"
   },
   "source": [
    "# Visualization of CNN Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:30.381268Z",
     "iopub.status.busy": "2023-09-18T17:35:30.380840Z",
     "iopub.status.idle": "2023-09-18T17:35:30.667804Z",
     "shell.execute_reply": "2023-09-18T17:35:30.666802Z",
     "shell.execute_reply.started": "2023-09-18T17:35:30.381234Z"
    },
    "id": "4d81f195-4a6b-4de2-a03e-e9c71b551559",
    "outputId": "9a8af4bf-bef8-4790-9238-f0dbc9ed0d7c"
   },
   "outputs": [],
   "source": [
    "n_example = 50\n",
    "\n",
    "# let's look at an example image from the validation dataset:\n",
    "x_example = val[n_example].detach()  # [28, 28]\n",
    "plt.imshow(x_example.cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:30.670663Z",
     "iopub.status.busy": "2023-09-18T17:35:30.670022Z",
     "iopub.status.idle": "2023-09-18T17:35:30.687096Z",
     "shell.execute_reply": "2023-09-18T17:35:30.686042Z",
     "shell.execute_reply.started": "2023-09-18T17:35:30.670627Z"
    },
    "id": "89e2475b-c025-4019-bbe9-122de8718596",
    "outputId": "92445aec-5219-4191-c006-d6248bad0b7f"
   },
   "outputs": [],
   "source": [
    "# predicted logits\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_logits = classifier(x_example.unsqueeze(dim=0).to(DEVICE))  # [1, 10]\n",
    "    for i in range(10):\n",
    "        print(f'{i}: {round(predicted_logits[0][i].item(), 2) :5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97ef96c4-23c2-43e7-97b1-906f709467ee"
   },
   "source": [
    "## Outputs of CNN Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:30.692571Z",
     "iopub.status.busy": "2023-09-18T17:35:30.692283Z",
     "iopub.status.idle": "2023-09-18T17:35:32.333792Z",
     "shell.execute_reply": "2023-09-18T17:35:32.332839Z",
     "shell.execute_reply.started": "2023-09-18T17:35:30.692547Z"
    },
    "id": "24d69dfc-df4d-4922-afd1-cec4c9037ce4",
    "outputId": "c1d13fe0-cd45-4e19-c266-5ed759f83aac"
   },
   "outputs": [],
   "source": [
    "# from [28, 28] to [batch_size, channel, 28, 28], i.e. [1, 1, 28, 28]\n",
    "x_unsqueezed = x_example.unsqueeze(dim=0)\n",
    "x_unsqueezed = x_unsqueezed.unsqueeze(dim=0)\n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    output_layer_1 = classifier.layer1(\n",
    "        x_unsqueezed.to(DEVICE)\n",
    "        ).detach()  # 1, 32, 14, 14\n",
    "\n",
    "fig = plt.figure(figsize=(25, 10))  # (width, height) in inches\n",
    "for i in range(32):\n",
    "    ax = fig.add_subplot(4,         # nrows\n",
    "                         10,        # ncols\n",
    "                         i+1,       # index (1-based)\n",
    "                         xticks=[],\n",
    "                         yticks=[])\n",
    "    image = output_layer_1[0][i]  # (14, 14)\n",
    "    ax.imshow(X=image.cpu(),\n",
    "              cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abc483b0-4a95-4443-84d5-db3138a2f616"
   },
   "source": [
    "### Show the outputs of CNN Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:32.336578Z",
     "iopub.status.busy": "2023-09-18T17:35:32.335414Z",
     "iopub.status.idle": "2023-09-18T17:35:35.931979Z",
     "shell.execute_reply": "2023-09-18T17:35:35.930996Z",
     "shell.execute_reply.started": "2023-09-18T17:35:32.336539Z"
    },
    "id": "4cecabc7-f944-494f-9fbe-24643d4280f7",
    "outputId": "362795b9-0ab0-4686-ebb1-afd5577eb75f"
   },
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    output_layer_2 = classifier.layer2(output_layer_1.to(DEVICE)).detach()  # [1, 64, 7, 7]\n",
    "\n",
    "fig = plt.figure(figsize=(25, 5))  # (width, height) in inches\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(\n",
    "                 4,         # nrows\n",
    "                 20,        # ncols\n",
    "                 i+1,       # index (1-based)\n",
    "                 xticks=[],\n",
    "                 yticks=[])\n",
    "    image = output_layer_2[0][i]  # (7, 7)\n",
    "    ax.imshow(X=image.cpu(),\n",
    "              cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6440edfb-98e1-4858-b972-548430104c32"
   },
   "source": [
    "### Show the outputs of CNN Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T17:35:35.934165Z",
     "iopub.status.busy": "2023-09-18T17:35:35.933551Z",
     "iopub.status.idle": "2023-09-18T17:35:42.013863Z",
     "shell.execute_reply": "2023-09-18T17:35:42.012904Z",
     "shell.execute_reply.started": "2023-09-18T17:35:35.934131Z"
    },
    "id": "25f9ddeb-066a-47f9-ad29-b709207e9bfb",
    "outputId": "4defba48-4be9-49f4-8fbd-1681c574ccd1"
   },
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    output_layer_3 = classifier.layer3(output_layer_2.to(DEVICE)).detach()  # [1, 128, 4, 4]\n",
    "\n",
    "print(output_layer_3.shape)\n",
    "    \n",
    "fig = plt.figure(figsize=(25, 5))  # (width, height) in inches\n",
    "for i in range(128):\n",
    "    ax = fig.add_subplot(\n",
    "                 5,         # nrows\n",
    "                 30,        # ncols\n",
    "                 i+1,       # index (1-based)\n",
    "                 xticks=[],\n",
    "                 yticks=[])\n",
    "    image = output_layer_3[0][i]  # (28, 28)\n",
    "    ax.imshow(X=image.cpu(),\n",
    "              cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2548b830-0b64-4538-bbb4-0a285d5b0c9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
